{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8e3e19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from hyperimpute.plugins.utils.metrics import RMSE\n",
    "from hyperimpute.plugins.utils.simulate import simulate_nan\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52d7db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperimpute.plugins.imputers import Imputers, ImputerPlugin\n",
    "\n",
    "imputers = Imputers()\n",
    "\n",
    "imputers.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d07d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from hyperimpute.plugins.imputers import Imputers\n",
    "from hyperimpute.utils.benchmarks import compare_models\n",
    "\n",
    "imputer = Imputers().get(\n",
    "    \"hyperimpute\",  # the name of the imputation method.\n",
    "    # The rest of the kwargs are specific to the method\n",
    "    # optimizer: str. The optimizer to use: simple, hyperband, bayesian\n",
    "    optimizer=\"hyperband\",\n",
    "    # classifier_seed: list. Model search pool for categorical columns.\n",
    "    classifier_seed=[\"logistic_regression\", \"catboost\", \"xgboost\", \"random_forest\"],\n",
    "    # regression_seed: list. Model search pool for continuous columns.\n",
    "    regression_seed=[\n",
    "        \"linear_regression\",\n",
    "        \"catboost_regressor\",\n",
    "        \"xgboost_regressor\",\n",
    "        \"random_forest_regressor\",\n",
    "    ],\n",
    "    # class_threshold: int. how many max unique items must be in the column to be is associated with categorical\n",
    "    class_threshold=5,\n",
    "    # imputation_order: int. 0 - ascending, 1 - descending, 2 - random\n",
    "    imputation_order=2,\n",
    "    # n_inner_iter: int. number of imputation iterations\n",
    "    n_inner_iter=10,\n",
    "    # select_model_by_column: bool. If true, select a different model for each column. Else, it reuses the model chosen for the first column.\n",
    "    select_model_by_column=True,\n",
    "    # select_model_by_iteration: bool. If true, selects new models for each iteration. Else, it reuses the models chosen in the first iteration.\n",
    "    select_model_by_iteration=True,\n",
    "    # select_lazy: bool. If false, starts the optimizer on every column unless other restrictions apply. Else, if for the current iteration there is a trend(at least to columns of the same type got the same model from the optimizer), it reuses the same model class for all the columns without starting the optimizer.\n",
    "    select_lazy=True,\n",
    "    # select_patience: int. How many iterations without objective function improvement to wait.\n",
    "    select_patience=5,\n",
    ")\n",
    "\n",
    "# Load baseline dataset\n",
    "X, _ = load_diabetes(as_frame=True, return_X_y=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Dataset shape:\", X)\n",
    "\n",
    "# Run benchmarks\n",
    "_ = compare_models(\n",
    "    name=\"example\",\n",
    "    evaluated_model=imputer,\n",
    "    X_raw=X,\n",
    "    ref_methods=[\"gain\", \"miracle\"],\n",
    "    scenarios=[\"MAR\"],\n",
    "    miss_pct=[0.3, 0.5],\n",
    "    n_iter=2,\n",
    "    n_jobs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperimpute.plugins.imputers import Imputers\n",
    "from hyperimpute.utils.benchmarks import compare_models\n",
    "from dataset import Preprocessor\n",
    "\n",
    "# Load the gesture dataset\n",
    "prepper = Preprocessor('gesture')\n",
    "X = prepper.encodeDf('OHE', prepper.df_train)  # One-hot encode categorical columns\n",
    "X = prepper.decodeNp('OHE', X)  # If you want to get back a DataFrame with numeric columns\n",
    "\n",
    "print(\"Dataset shape:\", X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2756679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from dataset import Preprocessor\n",
    "from hyperimpute.plugins.imputers import Imputers\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Train HyperImpute on tabular datasets')\n",
    "    parser.add_argument('--dataname', type=str, default='gesture', help='Name of dataset.')\n",
    "    parser.add_argument('--mask', type=str, default='MCAR', help='Masking mechanism: MCAR, MAR, MNAR_logistic_T2')\n",
    "    parser.add_argument('--ratio', type=float, default=0.3, help='Missing ratio')\n",
    "    parser.add_argument('--num_trials', type=int, default=5, help='Number of mask trials')\n",
    "    if any('ipykernel' in arg or 'jupyter' in arg for arg in sys.argv):\n",
    "        return parser.parse_args(args=[])\n",
    "    else:\n",
    "        return parser.parse_args()\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "    dataname = args.dataname\n",
    "    mask_type = args.mask\n",
    "    ratio = args.ratio\n",
    "    num_trials = args.num_trials\n",
    "\n",
    "    print(f\"Dataset: {dataname}, Mask: {mask_type}, Ratio: {ratio}, Trials: {num_trials}\")\n",
    "\n",
    "    prepper = Preprocessor(dataname)\n",
    "    train_X = prepper.encodeDf('OHE', prepper.df_train)\n",
    "    num_numeric = prepper.numerical_indices_np_end\n",
    "\n",
    "    np.random.seed(42)\n",
    "    masks = [(np.random.rand(*train_X.shape) < ratio) for _ in range(num_trials)]\n",
    "\n",
    "    MSEs = []\n",
    "    models_dir = f'saved_models/{dataname}/'\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "    imputer = Imputers().get(\n",
    "        \"hyperimpute\",\n",
    "        optimizer=\"hyperband\",\n",
    "        classifier_seed=[\"logistic_regression\", \"catboost\", \"xgboost\", \"random_forest\"],\n",
    "        regression_seed=[\n",
    "            \"linear_regression\",\n",
    "            \"catboost_regressor\",\n",
    "            \"xgboost_regressor\",\n",
    "            \"random_forest_regressor\",\n",
    "        ],\n",
    "        class_threshold=5,\n",
    "        imputation_order=2,\n",
    "        n_inner_iter=10,\n",
    "        select_model_by_column=True,\n",
    "        select_model_by_iteration=True,\n",
    "        select_lazy=True,\n",
    "        select_patience=5,\n",
    "    )\n",
    "\n",
    "    for trial in tqdm(range(num_trials), desc='HyperImpute Training'):\n",
    "        X_miss = train_X.copy()\n",
    "        X_miss[masks[trial]] = np.nan\n",
    "\n",
    "        imputer.fit(X_miss)\n",
    "        X_imputed = imputer.transform(X_miss)\n",
    "\n",
    "        mse = np.nanmean((X_imputed[masks[trial]] - train_X[masks[trial]]) ** 2)\n",
    "        MSEs.append(mse)\n",
    "\n",
    "        imputer.save(os.path.join(models_dir, f\"hyperimpute_trial{trial}.pkl\"))\n",
    "        print(f\"Trial {trial}: MSE={mse:.6f}\")\n",
    "\n",
    "    print(f\"Avg MSE: {np.mean(MSEs):.6f} ± {np.std(MSEs):.6f}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca2557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def masked_mse(\n",
    "    X_pred: pd.DataFrame,\n",
    "    X_true: pd.DataFrame,\n",
    "    mask: pd.DataFrame,\n",
    "    mask_marks_missing: bool = True,\n",
    "    by_column: bool = False,\n",
    ") -> float | tuple[float, pd.Series]:\n",
    "    \"\"\"\n",
    "    计算只在 mask 指定的单元格上的 MSE（仅数值列）。\n",
    "    参数\n",
    "    ----\n",
    "    X_pred: 预测/填补后的表（DataFrame）\n",
    "    X_true: 原始完整表（DataFrame）\n",
    "    mask:   与表同形状的布尔/0-1 DataFrame。True 表示“评估这些位置”。\n",
    "    mask_marks_missing: 若你的 mask 的 True 表示“未遮蔽/可见”，设为 False 以取反。\n",
    "    by_column: True 时同时返回按列的 MSE（Series）\n",
    "    \"\"\"\n",
    "    # 对齐索引与列，确保同形状\n",
    "    X_pred = X_pred.reindex_like(X_true)\n",
    "    mask = mask.reindex_like(X_true)\n",
    "\n",
    "    # 只保留数值列\n",
    "    num_cols = X_true.select_dtypes(include=[np.number]).columns\n",
    "    Xp = X_pred[num_cols]\n",
    "    Xt = X_true[num_cols]\n",
    "    M  = mask[num_cols].astype(bool)\n",
    "\n",
    "    # 如果 mask 的 True 不是“被遮蔽/需要评估”的含义，则取反\n",
    "    if not mask_marks_missing:\n",
    "        M = ~M\n",
    "\n",
    "    # 计算误差（只在 M==True 的位置）\n",
    "    diff = (Xp.to_numpy() - Xt.to_numpy())\n",
    "    M_np = M.to_numpy()\n",
    "    mse_all = float(np.nanmean((diff**2)[M_np]))  # 全局 MSE\n",
    "\n",
    "    if not by_column:\n",
    "        return mse_all\n",
    "\n",
    "    # 按列 MSE\n",
    "    per_col = {}\n",
    "    for j, col in enumerate(num_cols):\n",
    "        mj = M_np[:, j]\n",
    "        per_col[col] = float(np.nanmean((diff[:, j]**2)[mj])) if mj.any() else np.nan\n",
    "    return mse_all, pd.Series(per_col, name=\"mse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3f2c9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def ampute(x, mechanism: str, p_miss: float):\n",
    "    \"\"\"\n",
    "    返回：\n",
    "      X_true: 原始 DataFrame\n",
    "      X_miss: 注入缺失后的 DataFrame\n",
    "      M:      布尔掩码，True 表示该单元格被遮蔽/缺失\n",
    "    \"\"\"\n",
    "    # 你已有的 simulate_nan\n",
    "    x_sim = simulate_nan(np.asarray(x), p_miss, mechanism)\n",
    "\n",
    "    X_true = pd.DataFrame(x)                          # 原始\n",
    "    X_miss = pd.DataFrame(x_sim[\"X_incomp\"])          # 注入缺失\n",
    "    M_raw  = pd.DataFrame(x_sim[\"mask\"]).astype(bool) # 原始掩码 -> bool\n",
    "\n",
    "    # 自动判定 True 的语义是否与缺失一致（与 X_miss 的 NaN 对齐）\n",
    "    miss_pos = X_miss.isna().to_numpy()\n",
    "    same = (M_raw.to_numpy() == miss_pos).mean()\n",
    "    inv  = ((~M_raw).to_numpy() == miss_pos).mean()\n",
    "    M = M_raw if same >= inv else ~M_raw\n",
    "\n",
    "    # 对齐索引与列名\n",
    "    M.index, M.columns = X_true.index, X_true.columns\n",
    "    X_miss.columns = X_true.columns\n",
    "    X_miss.index   = X_true.index\n",
    "    return X_true, X_miss, M\n",
    "\n",
    "\n",
    "def masked_mse(\n",
    "    X_pred: pd.DataFrame,\n",
    "    X_true: pd.DataFrame,\n",
    "    mask: pd.DataFrame,\n",
    "    true_means_missing: str = \"auto\",   # \"auto\" | \"missing\" | \"observed\"\n",
    "    X_miss: pd.DataFrame | None = None, # 若提供，可用于自动判定\n",
    "    by_column: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    只在 mask==True 的位置计算数值列 MSE。\n",
    "    - true_means_missing=\"auto\": 若提供 X_miss，则用 X_miss.isna() 判定；否则默认为 True=missing\n",
    "    - \"missing\": 直接认为 True=missing\n",
    "    - \"observed\": 认为 True=observed，会自动取反\n",
    "    \"\"\"\n",
    "    # 对齐形状\n",
    "    X_true = X_true.copy()\n",
    "    X_pred = X_pred.reindex_like(X_true)\n",
    "    M = mask.reindex_like(X_true).astype(bool)\n",
    "\n",
    "    # 处理 True 的语义\n",
    "    if true_means_missing == \"auto\":\n",
    "        if X_miss is not None:\n",
    "            miss_pos = X_miss.reindex_like(X_true).isna().to_numpy()\n",
    "            same = (M.to_numpy() == miss_pos).mean()\n",
    "            inv  = ((~M).to_numpy() == miss_pos).mean()\n",
    "            if inv > same:\n",
    "                M = ~M\n",
    "        # 若无 X_miss，默认 True=missing（不处理）\n",
    "    elif true_means_missing == \"observed\":\n",
    "        M = ~M\n",
    "    # else \"missing\": 不处理\n",
    "\n",
    "    # 仅数值列\n",
    "    num_cols = X_true.select_dtypes(include=[np.number]).columns\n",
    "    if len(num_cols) == 0:\n",
    "        return (np.nan, pd.Series(dtype=float, name=\"mse\")) if by_column else np.nan\n",
    "\n",
    "    Xp = X_pred[num_cols].to_numpy()\n",
    "    Xt = X_true[num_cols].to_numpy()\n",
    "    Mm = M[num_cols].to_numpy()\n",
    "\n",
    "    if Mm.sum() == 0:\n",
    "        return (np.nan, pd.Series({c: np.nan for c in num_cols}, name=\"mse\")) if by_column else np.nan\n",
    "\n",
    "    diff2 = (Xp - Xt) ** 2\n",
    "    overall = float(np.nanmean(diff2[ Mm ]))\n",
    "\n",
    "    if not by_column:\n",
    "        return overall\n",
    "\n",
    "    per_col = {}\n",
    "    for j, c in enumerate(num_cols):\n",
    "        mj = Mm[:, j]\n",
    "        per_col[c] = float(np.nanmean(diff2[:, j][mj])) if mj.any() else np.nan\n",
    "    return overall, pd.Series(per_col, name=\"mse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf9ecd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame (X_true):      a     b\n",
      "0  1.0  10.0\n",
      "1  2.0  20.0\n",
      "2  3.0  30.0      a     b\n",
      "0  1.0  10.0\n",
      "1  2.0  20.0\n",
      "2  3.0  30.0        a      b\n",
      "0  False  False\n",
      "1  False  False\n",
      "2  False  False\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "masked_mse() got an unexpected keyword argument 'true_means_missing'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m X_pred = model.fit_transform(X_miss)  \u001b[38;5;66;03m# 或已训练好的 imputer.transform(X_miss)\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# 计算只在被遮蔽位置上的 MSE（自动识别 True 的语义）\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m mse_all, mse_by_col = \u001b[43mmasked_mse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_means_missing\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_miss\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_miss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_column\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMSE:\u001b[39m\u001b[33m\"\u001b[39m, mse_all)\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(mse_by_col.sort_values(ascending=\u001b[38;5;28;01mFalse\u001b[39;00m).head())\n",
      "\u001b[31mTypeError\u001b[39m: masked_mse() got an unexpected keyword argument 'true_means_missing'"
     ]
    }
   ],
   "source": [
    "# 生成被遮蔽数据与布尔 mask（True=缺失，若 simulate_nan 语义相反会自动修正）\n",
    "# —— 原始真值表（X_true）——\n",
    "df = pd.DataFrame(\n",
    "    [[1.0, 10.0],\n",
    "     [2.0, 20.0],\n",
    "     [3.0, 30.0]],\n",
    "    columns=[\"a\",\"b\"]\n",
    ")\n",
    "X_true, X_miss, M = ampute(df, mechanism=\"MCAR\", p_miss=0.3)\n",
    "print(\"Original DataFrame (X_true):\", X_true, X_miss, M)\n",
    "\n",
    "# 用你的 imputer 复原\n",
    "model = Imputers().get(\"gain\", random_state=42)\n",
    "X_pred = model.fit_transform(X_miss)  # 或已训练好的 imputer.transform(X_miss)\n",
    "\n",
    "# 计算只在被遮蔽位置上的 MSE（自动识别 True 的语义）\n",
    "mse_all, mse_by_col = masked_mse(X_pred, X_true, M, true_means_missing=\"auto\", X_miss=X_miss, by_column=True)\n",
    "print(\"MSE:\", mse_all)\n",
    "print(mse_by_col.sort_values(ascending=False).head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13fa85d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a     b\n",
      "0  1.0  12.0\n",
      "1  1.7  20.0\n",
      "2  2.6  29.0      a     b\n",
      "0  1.0  10.0\n",
      "1  2.0  20.0\n",
      "2  3.0  30.0        a      b\n",
      "0  False   True\n",
      "1   True  False\n",
      "2   True   True\n",
      "MSE = 1.3125\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# —— 原始真值表（X_true）——\n",
    "X_true = pd.DataFrame(\n",
    "    [[1.0, 10.0],\n",
    "     [2.0, 20.0],\n",
    "     [3.0, 30.0]],\n",
    "    columns=[\"a\",\"b\"]\n",
    ")\n",
    "\n",
    "# —— 预测/填补后的表（X_pred）——\n",
    "X_pred = pd.DataFrame(\n",
    "    [[1.0, 12.0],   # b: 12 vs 10 → diff=+2\n",
    "     [1.7, 20.0],   # a: 1.7 vs 2.0 → diff=-0.3\n",
    "     [2.6, 29.0]],  # a: 2.6 vs 3.0 → diff=-0.4;  b: 29 vs 30 → diff=-1\n",
    "    columns=[\"a\",\"b\"]\n",
    ")\n",
    "\n",
    "# —— 评估用的 mask（True 表示该单元格被遮蔽过 → 要计入 MSE）——\n",
    "mask = pd.DataFrame(\n",
    "    [[False, True ],\n",
    "     [ True, False],\n",
    "     [ True, True ]],\n",
    "    columns=[\"a\",\"b\"]\n",
    ")\n",
    "\n",
    "def masked_mse(X_pred, X_true, mask, mask_marks_missing=True):\n",
    "    # 只算数值列；mask==True 的位置才计入\n",
    "    num_cols = X_true.select_dtypes(include=[np.number]).columns\n",
    "    Xp = X_pred[num_cols].to_numpy()\n",
    "    Xt = X_true[num_cols].to_numpy()\n",
    "    M  = mask[num_cols].astype(bool).to_numpy()\n",
    "    if not mask_marks_missing:\n",
    "        M = ~M\n",
    "    return float(np.nanmean(((Xp - Xt) ** 2)[M]))\n",
    "\n",
    "print(X_pred, X_true, mask)\n",
    "mse = masked_mse(X_pred, X_true, mask, mask_marks_missing=True)\n",
    "print(\"MSE =\", mse)   # 期望：1.3125\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac04fbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame (X_true):    0  1  2  3\n",
      "0  1  1  1  1\n",
      "1  4  5  3  8\n",
      "2  3  3  9  9\n",
      "3  2  2  2  2\n",
      "Missing data:    0  1    2    3\n",
      "0  1  1  1.0  1.0\n",
      "1  4  5  NaN  NaN\n",
      "2  3  3  9.0  9.0\n",
      "3  2  2  2.0  2.0\n",
      "miracle outpt      0    1         2         3\n",
      "0  1.0  1.0  1.000000  1.000000\n",
      "1  4.0  5.0 -1.340026 -1.900554\n",
      "2  3.0  3.0  9.000000  9.000000\n",
      "3  2.0  2.0  2.000000  2.000000\n",
      "hyperimpute output:    0  1    2    3\n",
      "0  1  1  1.0  1.0\n",
      "1  4  5  9.0  9.0\n",
      "2  3  3  9.0  9.0\n",
      "3  2  2  2.0  2.0\n",
      "gain output:      0    1         2         3\n",
      "0  1.0  1.0  1.000000  1.000000\n",
      "1  4.0  5.0  7.284791  7.642774\n",
      "2  3.0  3.0  9.000000  9.000000\n",
      "3  2.0  2.0  2.000000  2.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hyperimpute.plugins.imputers import Imputers\n",
    "from hyperimpute.plugins.utils.simulate import simulate_nan\n",
    "\n",
    "def ampute(x, mechanism, p_miss):\n",
    "    x_simulated = simulate_nan(np.asarray(x), p_miss, mechanism)\n",
    "\n",
    "    mask = x_simulated[\"mask\"]\n",
    "    x_miss = x_simulated[\"X_incomp\"]\n",
    "    print(x_miss, mask)\n",
    "    # return pd.DataFrame(x), pd.DataFrame(x_miss, columns = x.columns), pd.DataFrame(mask, columns = x.columns)\n",
    "    return pd.DataFrame(x), pd.DataFrame(x_miss), pd.DataFrame(mask)\n",
    "\n",
    "\n",
    "\n",
    "X_miss = pd.DataFrame([[1, 1, 1, 1], [4, 5, np.nan, np.nan], [3, 3, 9, 9], [2, 2, 2, 2]])\n",
    "\n",
    "\n",
    "\n",
    "X_true = pd.DataFrame(\n",
    "    [[1, 1, 1, 1],\n",
    "     [4, 5, 3, 8],\n",
    "     [3, 3, 9, 9],\n",
    "     [2, 2, 2, 2]],\n",
    "     # 注意：这里的列名与后续 ampute 的一致\n",
    "    # columns=[\"a\",\"b\"]\n",
    ")\n",
    "print(\"Original DataFrame (X_true):\", X_true)\n",
    "print(\"Missing data:\", X_miss)\n",
    "\n",
    "# 用你的 imputer 复原\n",
    "model = Imputers().get(\"miracle\", random_state=42)\n",
    "X_pred = model.fit_transform(X_miss.copy())  # 或已训练好的 imputer.transform(X_miss)\n",
    "\n",
    "plugin1 = Imputers().get(\n",
    "    \"hyperimpute\",\n",
    "    # optimizer=\"hyperband\",\n",
    "    # classifier_seed=[\"logistic_regression\"],\n",
    "    # regression_seed=[\"linear_regression\"],\n",
    ")\n",
    "out = plugin1.fit_transform(X_miss.copy())\n",
    "\n",
    "plugin2 = Imputers().get(\n",
    "    \"gain\",\n",
    "    # optimizer=\"hyperband\",\n",
    "    # classifier_seed=[\"logistic_regression\"],\n",
    "    # regression_seed=[\"linear_regression\"],\n",
    ")\n",
    "out2 = plugin2.fit_transform(X_miss.copy())\n",
    "\n",
    "print(\"miracle outpt\", X_pred)\n",
    "print(\"hyperimpute output:\", out)\n",
    "print(\"gain output:\", out2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataImputation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
