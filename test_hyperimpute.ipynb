{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8e3e19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from hyperimpute.plugins.utils.metrics import RMSE\n",
    "from hyperimpute.plugins.utils.simulate import simulate_nan\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e52d7db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['median',\n",
       " 'sklearn_ice',\n",
       " 'missforest',\n",
       " 'ice',\n",
       " 'gain',\n",
       " 'mice',\n",
       " 'miracle',\n",
       " 'hyperimpute',\n",
       " 'miwae',\n",
       " 'softimpute',\n",
       " 'sinkhorn',\n",
       " 'nop',\n",
       " 'EM',\n",
       " 'most_frequent',\n",
       " 'mean',\n",
       " 'sklearn_missforest']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hyperimpute.plugins.imputers import Imputers, ImputerPlugin\n",
    "\n",
    "imputers = Imputers()\n",
    "\n",
    "imputers.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49d07d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:           age       sex       bmi        bp        s1        s2        s3  \\\n",
      "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
      "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
      "2    0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
      "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
      "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
      "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
      "439  0.041708  0.050680 -0.015906  0.017293 -0.037344 -0.013840 -0.024993   \n",
      "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
      "441 -0.045472 -0.044642 -0.073030 -0.081413  0.083740  0.027809  0.173816   \n",
      "\n",
      "           s4        s5        s6  \n",
      "0   -0.002592  0.019907 -0.017646  \n",
      "1   -0.039493 -0.068332 -0.092204  \n",
      "2   -0.002592  0.002861 -0.025930  \n",
      "3    0.034309  0.022688 -0.009362  \n",
      "4   -0.002592 -0.031988 -0.046641  \n",
      "..        ...       ...       ...  \n",
      "437 -0.002592  0.031193  0.007207  \n",
      "438  0.034309 -0.018114  0.044485  \n",
      "439 -0.011080 -0.046883  0.015491  \n",
      "440  0.026560  0.044529 -0.025930  \n",
      "441 -0.039493 -0.004222  0.003064  \n",
      "\n",
      "[442 rows x 10 columns]\n",
      "WARNING:tensorflow:From /Users/yuandouwang/miniconda3/envs/dataImputation/lib/python3.12/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755505280.764436 23521409 mlir_graph_optimization_pass.cc:437] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE score\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>miss_pct [0, 1]</th>\n",
       "      <th>Evaluated: hyperimpute</th>\n",
       "      <th>gain</th>\n",
       "      <th>miracle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAR</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1299 +/- 0.005</td>\n",
       "      <td>0.1488 +/- 0.0053</td>\n",
       "      <td>4.2099 +/- 0.3155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAR</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2303 +/- 0.1315</td>\n",
       "      <td>0.2262 +/- 0.0843</td>\n",
       "      <td>4.6731 +/- 0.6089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scenario  miss_pct [0, 1] Evaluated: hyperimpute               gain  \\\n",
       "0      MAR              0.3       0.1299 +/- 0.005  0.1488 +/- 0.0053   \n",
       "1      MAR              0.5      0.2303 +/- 0.1315  0.2262 +/- 0.0843   \n",
       "\n",
       "             miracle  \n",
       "0  4.2099 +/- 0.3155  \n",
       "1  4.6731 +/- 0.6089  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================\n",
      "\n",
      "Wasserstein score\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>miss_pct [0, 1]</th>\n",
       "      <th>Evaluated: hyperimpute</th>\n",
       "      <th>gain</th>\n",
       "      <th>miracle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAR</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0663 +/- 0.0032</td>\n",
       "      <td>0.079 +/- 0.0014</td>\n",
       "      <td>4.9567 +/- 0.3283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAR</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.115 +/- 0.0034</td>\n",
       "      <td>0.2231 +/- 0.0779</td>\n",
       "      <td>9.0983 +/- 1.4954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scenario  miss_pct [0, 1] Evaluated: hyperimpute               gain  \\\n",
       "0      MAR              0.3      0.0663 +/- 0.0032   0.079 +/- 0.0014   \n",
       "1      MAR              0.5       0.115 +/- 0.0034  0.2231 +/- 0.0779   \n",
       "\n",
       "             miracle  \n",
       "0  4.9567 +/- 0.3283  \n",
       "1  9.0983 +/- 1.4954  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from hyperimpute.plugins.imputers import Imputers\n",
    "from hyperimpute.utils.benchmarks import compare_models\n",
    "\n",
    "imputer = Imputers().get(\n",
    "    \"hyperimpute\",  # the name of the imputation method.\n",
    "    # The rest of the kwargs are specific to the method\n",
    "    # optimizer: str. The optimizer to use: simple, hyperband, bayesian\n",
    "    optimizer=\"hyperband\",\n",
    "    # classifier_seed: list. Model search pool for categorical columns.\n",
    "    classifier_seed=[\"logistic_regression\", \"catboost\", \"xgboost\", \"random_forest\"],\n",
    "    # regression_seed: list. Model search pool for continuous columns.\n",
    "    regression_seed=[\n",
    "        \"linear_regression\",\n",
    "        \"catboost_regressor\",\n",
    "        \"xgboost_regressor\",\n",
    "        \"random_forest_regressor\",\n",
    "    ],\n",
    "    # class_threshold: int. how many max unique items must be in the column to be is associated with categorical\n",
    "    class_threshold=5,\n",
    "    # imputation_order: int. 0 - ascending, 1 - descending, 2 - random\n",
    "    imputation_order=2,\n",
    "    # n_inner_iter: int. number of imputation iterations\n",
    "    n_inner_iter=10,\n",
    "    # select_model_by_column: bool. If true, select a different model for each column. Else, it reuses the model chosen for the first column.\n",
    "    select_model_by_column=True,\n",
    "    # select_model_by_iteration: bool. If true, selects new models for each iteration. Else, it reuses the models chosen in the first iteration.\n",
    "    select_model_by_iteration=True,\n",
    "    # select_lazy: bool. If false, starts the optimizer on every column unless other restrictions apply. Else, if for the current iteration there is a trend(at least to columns of the same type got the same model from the optimizer), it reuses the same model class for all the columns without starting the optimizer.\n",
    "    select_lazy=True,\n",
    "    # select_patience: int. How many iterations without objective function improvement to wait.\n",
    "    select_patience=5,\n",
    ")\n",
    "\n",
    "# Load baseline dataset\n",
    "X, _ = load_diabetes(as_frame=True, return_X_y=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Dataset shape:\", X)\n",
    "\n",
    "# Run benchmarks\n",
    "_ = compare_models(\n",
    "    name=\"example\",\n",
    "    evaluated_model=imputer,\n",
    "    X_raw=X,\n",
    "    ref_methods=[\"gain\", \"miracle\"],\n",
    "    scenarios=[\"MAR\"],\n",
    "    miss_pct=[0.3, 0.5],\n",
    "    n_iter=2,\n",
    "    n_jobs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "499b010f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: [[ 3.542000e-05  6.820860e-03  7.064900e-04 ...  1.237900e-03\n",
      "   7.116800e-04  3.780600e-04]\n",
      " [ 2.512460e-03  2.246600e-04 -4.145400e-04 ...  2.498000e-04\n",
      "   1.759500e-04  1.803300e-04]\n",
      " [-1.333400e-04 -1.014410e-02  6.468200e-04 ...  1.356980e-03\n",
      "   1.398190e-03  1.000380e-03]\n",
      " ...\n",
      " [-1.005159e-02 -9.317200e-03 -4.466700e-03 ...  1.248690e-03\n",
      "   4.860510e-03  1.096630e-03]\n",
      " [-1.908400e-04 -9.545400e-04  4.951000e-05 ...  2.169000e-04\n",
      "   4.130000e-05  1.337100e-04]\n",
      " [-5.777000e-05  3.842300e-04  1.311000e-05 ...  9.653000e-05\n",
      "   2.932100e-04  9.357000e-05]]\n"
     ]
    }
   ],
   "source": [
    "from hyperimpute.plugins.imputers import Imputers\n",
    "from hyperimpute.utils.benchmarks import compare_models\n",
    "from dataset import Preprocessor\n",
    "\n",
    "# Load the gesture dataset\n",
    "prepper = Preprocessor('gesture')\n",
    "X = prepper.encodeDf('OHE', prepper.df_train)  # One-hot encode categorical columns\n",
    "X = prepper.decodeNp('OHE', X)  # If you want to get back a DataFrame with numeric columns\n",
    "\n",
    "print(\"Dataset shape:\", X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2756679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: gesture, Mask: MCAR, Ratio: 0.3, Trials: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HyperImpute Training:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from dataset import Preprocessor\n",
    "from hyperimpute.plugins.imputers import Imputers\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Train HyperImpute on tabular datasets')\n",
    "    parser.add_argument('--dataname', type=str, default='gesture', help='Name of dataset.')\n",
    "    parser.add_argument('--mask', type=str, default='MCAR', help='Masking mechanism: MCAR, MAR, MNAR_logistic_T2')\n",
    "    parser.add_argument('--ratio', type=float, default=0.3, help='Missing ratio')\n",
    "    parser.add_argument('--num_trials', type=int, default=5, help='Number of mask trials')\n",
    "    if any('ipykernel' in arg or 'jupyter' in arg for arg in sys.argv):\n",
    "        return parser.parse_args(args=[])\n",
    "    else:\n",
    "        return parser.parse_args()\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "    dataname = args.dataname\n",
    "    mask_type = args.mask\n",
    "    ratio = args.ratio\n",
    "    num_trials = args.num_trials\n",
    "\n",
    "    print(f\"Dataset: {dataname}, Mask: {mask_type}, Ratio: {ratio}, Trials: {num_trials}\")\n",
    "\n",
    "    prepper = Preprocessor(dataname)\n",
    "    train_X = prepper.encodeDf('OHE', prepper.df_train)\n",
    "    num_numeric = prepper.numerical_indices_np_end\n",
    "\n",
    "    np.random.seed(42)\n",
    "    masks = [(np.random.rand(*train_X.shape) < ratio) for _ in range(num_trials)]\n",
    "\n",
    "    MSEs = []\n",
    "    models_dir = f'saved_models/{dataname}/'\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "    imputer = Imputers().get(\n",
    "        \"hyperimpute\",\n",
    "        optimizer=\"hyperband\",\n",
    "        classifier_seed=[\"logistic_regression\", \"catboost\", \"xgboost\", \"random_forest\"],\n",
    "        regression_seed=[\n",
    "            \"linear_regression\",\n",
    "            \"catboost_regressor\",\n",
    "            \"xgboost_regressor\",\n",
    "            \"random_forest_regressor\",\n",
    "        ],\n",
    "        class_threshold=5,\n",
    "        imputation_order=2,\n",
    "        n_inner_iter=10,\n",
    "        select_model_by_column=True,\n",
    "        select_model_by_iteration=True,\n",
    "        select_lazy=True,\n",
    "        select_patience=5,\n",
    "    )\n",
    "\n",
    "    for trial in tqdm(range(num_trials), desc='HyperImpute Training'):\n",
    "        X_miss = train_X.copy()\n",
    "        X_miss[masks[trial]] = np.nan\n",
    "\n",
    "        imputer.fit(X_miss)\n",
    "        X_imputed = imputer.transform(X_miss)\n",
    "\n",
    "        mse = np.nanmean((X_imputed[masks[trial]] - train_X[masks[trial]]) ** 2)\n",
    "        MSEs.append(mse)\n",
    "\n",
    "        imputer.save(os.path.join(models_dir, f\"hyperimpute_trial{trial}.pkl\"))\n",
    "        print(f\"Trial {trial}: MSE={mse:.6f}\")\n",
    "\n",
    "    print(f\"Avg MSE: {np.mean(MSEs):.6f} Â± {np.std(MSEs):.6f}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataImputation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
